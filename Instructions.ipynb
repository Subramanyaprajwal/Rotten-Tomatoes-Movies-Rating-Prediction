{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSa3eoPTH2VR"
   },
   "source": [
    "#**Rotten Tomatoes Movies Rating Prediction**\n",
    "\n",
    "**Assignment**\n",
    "\n",
    "In this project, you are given large datasets from Rotten Tomatoes - a popular online review aggregator for film and television. Your task is to build a high performing classification algorithm to predict whether a particular movie on Rotten Tomatoes is labeled as 'Rotten', 'Fresh', or 'Certified-Fresh'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzrbWKGJIFea"
   },
   "source": [
    "## |**Data Description**\n",
    "\n",
    "**There are 2 datasets**\n",
    "\n",
    "1. rotten_tomatoes_movies.csv - contains basic information about each movie listed on Rotten Tomatoes; each row represents one movie;\n",
    "2. rotten_tomatoes_critic_reviews_50k.tsv - contains 50.000 individual reviews by Rotten Tomatoes critics; each row represents one review corresponding to a movie;\n",
    "\n",
    "rotten_tomatoes_movies dataset contains the following columns:\n",
    "\n",
    "- rotten_tomatoes_link - movie ID\n",
    "- movie_title - title of the movie as displayed on the Rotten Tomatoes website\n",
    "- movie_info - brief description of the movie\n",
    "- critics_consensus - comment from Rotten Tomatoes\n",
    "- content_rating - category based on the movie suitability for audience\n",
    "- genres - movie genres separated by commes, if multiple\n",
    "- directors - name of director(s)\n",
    "- authors - name of author(s)\n",
    "- actors - name of actors\n",
    "- original_release_date - date in which the movie has been released in  \n",
    "   theatres, in YYY-MM-DD format\n",
    "- streaming_release_date - date in which the movie has been released on\n",
    "   streaming platforms, in YYY-MM-DD format\n",
    "- runtime - duration of the movie in minutes\n",
    "- production_company - name of a studio/company that produced the movie\n",
    "- tomatometer_status - a label assgined by Rotten Tomatoes: \"Fresh\",\n",
    "- \"Certified-Fresh\" or \"Rotten\"; this is the target variables in this challenge\n",
    "- tomatometer_rating - percentage of positive critic ratings\n",
    "- tomatometer_count - critic ratings counted for the calculation of the\n",
    "   tomatomer status\n",
    "- audience_status - a label assgined based on user ratings: \"Spilled\" or \"Upright\"\n",
    "- audience_rating - percentage of positive user ratings\n",
    "- audience_count - user ratings counted for the calculation of the audience\n",
    "   status\n",
    "- tomatometer_top_critics_count - number of ratings by top critics\n",
    "- tomatometer_fresh_critics_count - number of critic ratings labeled \"Fresh\"\n",
    "- tomatometer_rotten_critics_count - - number of critic ratings labeled \"Rotten\"\n",
    "\n",
    "\n",
    "rotten_tomatoes_critic_reviews_50k dataset contains the following columns:\n",
    "\n",
    "- rotten_tomatoes_link - movie ID\n",
    "- critic_name - name of critic who rated the movie\n",
    "- top_critic - boolean value that clarifies whether the critic is a top critic or not\n",
    "- publisher_name - name of the publisher for which the critic works\n",
    "- review_type - was the review labeled \"Fresh\" or \"Rotten\"?\n",
    "- review_score - review score provided by the critic\n",
    "- review_date - date of the review in YYYY-MM-DD format\n",
    "- review_content - text of the review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lp3fjBnzIFP0"
   },
   "source": [
    "## **Practicalities**\n",
    "\n",
    "Define, train and evaluate a predictive model that takes as the input the data provided. You may want to split the data into training, testing and validation sets, according to your discretion. Do not use external data for this project. You may use any algorithm of your choice or compare multiple models.\n",
    "\n",
    "Make sure that the solution reflects your entire thought process - it is more important how the code is structured rather than the final metrics. You are expected to spend no more than 3 hours working on this project.\n",
    "\n",
    "#### To download the dataset <a href=\"https://drive.google.com/drive/folders/1gfJwHeushdTfOeval0vceu0k1wOQ0kSv?usp=sharing\"> Click here </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies Dataset:\n",
      "                    rotten_tomatoes_link  \\\n",
      "0                              m/0814255   \n",
      "1                              m/0878835   \n",
      "2                                   m/10   \n",
      "3                 m/1000013-12_angry_men   \n",
      "4  m/1000079-20000_leagues_under_the_sea   \n",
      "\n",
      "                                         movie_title  \\\n",
      "0  Percy Jackson & the Olympians: The Lightning T...   \n",
      "1                                        Please Give   \n",
      "2                                                 10   \n",
      "3                    12 Angry Men (Twelve Angry Men)   \n",
      "4                       20,000 Leagues Under The Sea   \n",
      "\n",
      "                                          movie_info  \\\n",
      "0  Always trouble-prone, the life of teenager Per...   \n",
      "1  Kate (Catherine Keener) and her husband Alex (...   \n",
      "2  A successful, middle-aged Hollywood songwriter...   \n",
      "3  Following the closing arguments in a murder tr...   \n",
      "4  In 1866, Professor Pierre M. Aronnax (Paul Luk...   \n",
      "\n",
      "                                   critics_consensus content_rating  \\\n",
      "0  Though it may seem like just another Harry Pot...             PG   \n",
      "1  Nicole Holofcener's newest might seem slight i...              R   \n",
      "2  Blake Edwards' bawdy comedy may not score a pe...              R   \n",
      "3  Sidney Lumet's feature debut is a superbly wri...             NR   \n",
      "4  One of Disney's finest live-action adventures,...              G   \n",
      "\n",
      "                                              genres          directors  \\\n",
      "0  Action & Adventure, Comedy, Drama, Science Fic...     Chris Columbus   \n",
      "1                                             Comedy  Nicole Holofcener   \n",
      "2                                    Comedy, Romance      Blake Edwards   \n",
      "3                                    Classics, Drama       Sidney Lumet   \n",
      "4           Action & Adventure, Drama, Kids & Family  Richard Fleischer   \n",
      "\n",
      "                                      authors  \\\n",
      "0  Craig Titley, Chris Columbus, Rick Riordan   \n",
      "1                           Nicole Holofcener   \n",
      "2                               Blake Edwards   \n",
      "3                               Reginald Rose   \n",
      "4                                 Earl Felton   \n",
      "\n",
      "                                              actors original_release_date  \\\n",
      "0  Logan Lerman, Brandon T. Jackson, Alexandra Da...            2010-02-12   \n",
      "1  Catherine Keener, Amanda Peet, Oliver Platt, R...            2010-04-30   \n",
      "2  Dudley Moore, Bo Derek, Julie Andrews, Robert ...            1979-10-05   \n",
      "3  Martin Balsam, John Fiedler, Lee J. Cobb, E.G....            1957-04-13   \n",
      "4  James Mason, Kirk Douglas, Paul Lukas, Peter L...            1954-01-01   \n",
      "\n",
      "   ...      production_company  tomatometer_status tomatometer_rating  \\\n",
      "0  ...        20th Century Fox              Rotten               49.0   \n",
      "1  ...  Sony Pictures Classics     Certified-Fresh               87.0   \n",
      "2  ...             Waner Bros.               Fresh               67.0   \n",
      "3  ...    Criterion Collection     Certified-Fresh              100.0   \n",
      "4  ...                  Disney               Fresh               89.0   \n",
      "\n",
      "  tomatometer_count  audience_status  audience_rating audience_count  \\\n",
      "0             149.0          Spilled             53.0       254421.0   \n",
      "1             142.0          Upright             64.0        11574.0   \n",
      "2              24.0          Spilled             53.0        14684.0   \n",
      "3              54.0          Upright             97.0       105386.0   \n",
      "4              27.0          Upright             74.0        68918.0   \n",
      "\n",
      "   tomatometer_top_critics_count  tomatometer_fresh_critics_count  \\\n",
      "0                             43                               73   \n",
      "1                             44                              123   \n",
      "2                              2                               16   \n",
      "3                              6                               54   \n",
      "4                              5                               24   \n",
      "\n",
      "   tomatometer_rotten_critics_count  \n",
      "0                                76  \n",
      "1                                19  \n",
      "2                                 8  \n",
      "3                                 0  \n",
      "4                                 3  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "Reviews Dataset:\n",
      "  rotten_tomatoes_link      critic_name  top_critic           publisher_name  \\\n",
      "0            m/0814255  Andrew L. Urban       False           Urban Cinefile   \n",
      "1            m/0814255    Louise Keller       False           Urban Cinefile   \n",
      "2            m/0814255              NaN       False      FILMINK (Australia)   \n",
      "3            m/0814255     Ben McEachen       False  Sunday Mail (Australia)   \n",
      "4            m/0814255      Ethan Alter        True       Hollywood Reporter   \n",
      "\n",
      "  review_type review_score review_date  \\\n",
      "0       Fresh          NaN  2010-02-06   \n",
      "1       Fresh          NaN  2010-02-06   \n",
      "2       Fresh          NaN  2010-02-09   \n",
      "3       Fresh        3.5/5  2010-02-09   \n",
      "4      Rotten          NaN  2010-02-10   \n",
      "\n",
      "                                      review_content  \n",
      "0  A fantasy adventure that fuses Greek mythology...  \n",
      "1  Uma Thurman as Medusa, the gorgon with a coiff...  \n",
      "2  With a top-notch cast and dazzling special eff...  \n",
      "3  Whether audiences will get behind The Lightnin...  \n",
      "4  What's really lacking in The Lightning Thief i...  \n"
     ]
    }
   ],
   "source": [
    "movies_df = pd.read_csv('rotten_tomatoes_movies.csv')\n",
    "reviews_df = pd.read_csv('rotten_tomatoes_critic_reviews_50k.csv')\n",
    "\n",
    "print(\"Movies Dataset:\")\n",
    "print(movies_df.head())\n",
    "print(\"\\nReviews Dataset:\")\n",
    "print(reviews_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in Reviews Dataset after handling:\n",
      "rotten_tomatoes_link    0\n",
      "critic_name             0\n",
      "top_critic              0\n",
      "publisher_name          0\n",
      "review_type             0\n",
      "review_score            0\n",
      "review_date             0\n",
      "review_content          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# review scores\n",
    "def convert_review_score(score):\n",
    "    try:\n",
    "        # Extract the numeric part (e.g., '3.5' from '3.5/5')\n",
    "        return float(score.split('/')[0])\n",
    "    except (ValueError, AttributeError):\n",
    "        # Return NaN if conversion fails\n",
    "        return None\n",
    "\n",
    "# function to review_score column\n",
    "reviews_df['review_score'] = reviews_df['review_score'].apply(convert_review_score)\n",
    "\n",
    "\n",
    "reviews_df.fillna({\n",
    "    'critic_name': 'Unknown',\n",
    "    'review_score': reviews_df['review_score'].median(),\n",
    "    'review_content': 'No content'\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "print(\"\\nMissing values in Reviews Dataset after handling:\")\n",
    "print(reviews_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged Dataset Sample:\n",
      "  rotten_tomatoes_link      critic_name  top_critic           publisher_name  \\\n",
      "0            m/0814255  Andrew L. Urban       False           Urban Cinefile   \n",
      "1            m/0814255    Louise Keller       False           Urban Cinefile   \n",
      "2            m/0814255          Unknown       False      FILMINK (Australia)   \n",
      "3            m/0814255     Ben McEachen       False  Sunday Mail (Australia)   \n",
      "4            m/0814255      Ethan Alter        True       Hollywood Reporter   \n",
      "\n",
      "  review_type  review_score review_date  \\\n",
      "0       Fresh           3.0  2010-02-06   \n",
      "1       Fresh           3.0  2010-02-06   \n",
      "2       Fresh           3.0  2010-02-09   \n",
      "3       Fresh           3.5  2010-02-09   \n",
      "4      Rotten           3.0  2010-02-10   \n",
      "\n",
      "                                      review_content  \\\n",
      "0  A fantasy adventure that fuses Greek mythology...   \n",
      "1  Uma Thurman as Medusa, the gorgon with a coiff...   \n",
      "2  With a top-notch cast and dazzling special eff...   \n",
      "3  Whether audiences will get behind The Lightnin...   \n",
      "4  What's really lacking in The Lightning Thief i...   \n",
      "\n",
      "                                         movie_title  \\\n",
      "0  Percy Jackson & the Olympians: The Lightning T...   \n",
      "1  Percy Jackson & the Olympians: The Lightning T...   \n",
      "2  Percy Jackson & the Olympians: The Lightning T...   \n",
      "3  Percy Jackson & the Olympians: The Lightning T...   \n",
      "4  Percy Jackson & the Olympians: The Lightning T...   \n",
      "\n",
      "                                          movie_info  ... tomatometer_status  \\\n",
      "0  Always trouble-prone, the life of teenager Per...  ...             Rotten   \n",
      "1  Always trouble-prone, the life of teenager Per...  ...             Rotten   \n",
      "2  Always trouble-prone, the life of teenager Per...  ...             Rotten   \n",
      "3  Always trouble-prone, the life of teenager Per...  ...             Rotten   \n",
      "4  Always trouble-prone, the life of teenager Per...  ...             Rotten   \n",
      "\n",
      "  tomatometer_rating tomatometer_count audience_status audience_rating  \\\n",
      "0               49.0             149.0         Spilled            53.0   \n",
      "1               49.0             149.0         Spilled            53.0   \n",
      "2               49.0             149.0         Spilled            53.0   \n",
      "3               49.0             149.0         Spilled            53.0   \n",
      "4               49.0             149.0         Spilled            53.0   \n",
      "\n",
      "  audience_count tomatometer_top_critics_count  \\\n",
      "0       254421.0                            43   \n",
      "1       254421.0                            43   \n",
      "2       254421.0                            43   \n",
      "3       254421.0                            43   \n",
      "4       254421.0                            43   \n",
      "\n",
      "  tomatometer_fresh_critics_count  tomatometer_rotten_critics_count  \\\n",
      "0                              73                                76   \n",
      "1                              73                                76   \n",
      "2                              73                                76   \n",
      "3                              73                                76   \n",
      "4                              73                                76   \n",
      "\n",
      "                                       combined_text  \n",
      "0  A fantasy adventure that fuses Greek mythology...  \n",
      "1  Uma Thurman as Medusa, the gorgon with a coiff...  \n",
      "2  With a top-notch cast and dazzling special eff...  \n",
      "3  Whether audiences will get behind The Lightnin...  \n",
      "4  What's really lacking in The Lightning Thief i...  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMerged Dataset Sample:\")\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (49957, 2) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m categorical_columns:\n\u001b[0;32m      8\u001b[0m     le \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m----> 9\u001b[0m     final_df[column] \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mfit_transform(final_df[column]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m))\n\u001b[0;32m     10\u001b[0m     label_encoders[column] \u001b[38;5;241m=\u001b[39m le\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:114\u001b[0m, in \u001b[0;36mLabelEncoder.fit_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[0;32m    102\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit label encoder and return encoded labels.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m        Encoded labels.\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m     y \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_, y \u001b[38;5;241m=\u001b[39m _unique(y, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1245\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, dtype, warn)\u001b[0m\n\u001b[0;32m   1234\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1235\u001b[0m             (\n\u001b[0;32m   1236\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA column-vector y was passed when a 1d array was\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1241\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1242\u001b[0m         )\n\u001b[0;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _asarray_with_order(xp\u001b[38;5;241m.\u001b[39mreshape(y, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)), order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m-> 1245\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1246\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my should be a 1d array, got an array of shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shape)\n\u001b[0;32m   1247\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (49957, 2) instead."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "categorical_columns = ['review_type', 'top_critic', 'publisher_name', 'content_rating', 'genres', 'directors', \n",
    "                        'authors', 'actors', 'production_company', 'audience_status']\n",
    "\n",
    "label_encoders = {}\n",
    "for column in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    final_df[column] = le.fit_transform(final_df[column].astype(str))\n",
    "    label_encoders[column] = le\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review_type             int32\n",
      "top_critic              int32\n",
      "publisher_name          int32\n",
      "content_rating          int32\n",
      "genres                  int32\n",
      "directors               int32\n",
      "authors                 int32\n",
      "actors                 object\n",
      "actors                float64\n",
      "production_company     object\n",
      "audience_status        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(final_df[categorical_columns].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['actors'] = final_df['actors'].astype(str)\n",
    "final_df['production_company'] = final_df['production_company'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              actors actors\n",
      "0  Logan Lerman, Brandon T. Jackson, Alexandra Da...    0.0\n",
      "1  Logan Lerman, Brandon T. Jackson, Alexandra Da...    0.0\n",
      "2  Logan Lerman, Brandon T. Jackson, Alexandra Da...    0.0\n",
      "3  Logan Lerman, Brandon T. Jackson, Alexandra Da...    0.0\n",
      "4  Logan Lerman, Brandon T. Jackson, Alexandra Da...    0.0\n",
      "5  Logan Lerman, Brandon T. Jackson, Alexandra Da...    0.0\n",
      "6  Logan Lerman, Brandon T. Jackson, Alexandra Da...    0.0\n",
      "7  Logan Lerman, Brandon T. Jackson, Alexandra Da...    0.0\n",
      "8  Logan Lerman, Brandon T. Jackson, Alexandra Da...    0.0\n",
      "9  Logan Lerman, Brandon T. Jackson, Alexandra Da...    0.0\n"
     ]
    }
   ],
   "source": [
    "print(final_df['actors'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Logan Lerman, Brandon T. Jackson, Alexandra Da...\n",
      "1    Logan Lerman, Brandon T. Jackson, Alexandra Da...\n",
      "2    Logan Lerman, Brandon T. Jackson, Alexandra Da...\n",
      "3    Logan Lerman, Brandon T. Jackson, Alexandra Da...\n",
      "4    Logan Lerman, Brandon T. Jackson, Alexandra Da...\n",
      "5    Logan Lerman, Brandon T. Jackson, Alexandra Da...\n",
      "6    Logan Lerman, Brandon T. Jackson, Alexandra Da...\n",
      "7    Logan Lerman, Brandon T. Jackson, Alexandra Da...\n",
      "8    Logan Lerman, Brandon T. Jackson, Alexandra Da...\n",
      "9    Logan Lerman, Brandon T. Jackson, Alexandra Da...\n",
      "Name: actors, dtype: object\n"
     ]
    }
   ],
   "source": [
    "final_df = final_df.loc[:, ~final_df.columns.duplicated()]\n",
    "\n",
    "# Converting the 'actors' column to string, replacing NaNs with 'Unknown'\n",
    "final_df['actors'] = final_df['actors'].astype(str).replace('nan', 'Unknown')\n",
    "\n",
    "print(final_df['actors'].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    20th Century Fox\n",
      "1    20th Century Fox\n",
      "2    20th Century Fox\n",
      "3    20th Century Fox\n",
      "4    20th Century Fox\n",
      "5    20th Century Fox\n",
      "6    20th Century Fox\n",
      "7    20th Century Fox\n",
      "8    20th Century Fox\n",
      "9    20th Century Fox\n",
      "Name: production_company, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Converting the 'production_company' column to string, replacing NaNs with 'Unknown'\n",
    "final_df['production_company'] = final_df['production_company'].astype(str).replace('nan', 'Unknown')\n",
    "\n",
    "print(final_df['production_company'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   review_type  top_critic  publisher_name  content_rating  genres  directors  \\\n",
      "0            0           0             927               3     195        434   \n",
      "1            0           0             927               3     195        434   \n",
      "2            0           0             516               3     195        434   \n",
      "3            0           0              72               3     195        434   \n",
      "4            1           1             658               3     195        434   \n",
      "5            1           1             724               3     195        434   \n",
      "6            1           0              26               3     195        434   \n",
      "7            0           1             613               3     195        434   \n",
      "8            0           0             772               3     195        434   \n",
      "9            0           1              98               3     195        434   \n",
      "\n",
      "   authors  actors  production_company  audience_status  \n",
      "0      512     807                   0                0  \n",
      "1      512     807                   0                0  \n",
      "2      512     807                   0                0  \n",
      "3      512     807                   0                0  \n",
      "4      512     807                   0                0  \n",
      "5      512     807                   0                0  \n",
      "6      512     807                   0                0  \n",
      "7      512     807                   0                0  \n",
      "8      512     807                   0                0  \n",
      "9      512     807                   0                0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# List of categorical columns\n",
    "categorical_columns = [\n",
    "    'review_type',\n",
    "    'top_critic',\n",
    "    'publisher_name',\n",
    "    'content_rating',\n",
    "    'genres',\n",
    "    'directors',\n",
    "    'authors',\n",
    "    'actors',\n",
    "    'production_company',\n",
    "    'audience_status'\n",
    "]\n",
    "\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "# Convertng categorical columns to numeric\n",
    "for column in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    final_df[column] = le.fit_transform(final_df[column].astype(str))\n",
    "    label_encoders[column] = le\n",
    "\n",
    "print(final_df[categorical_columns].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (39965, 1025)\n",
      "Testing set size: (9992, 1025)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target_column = 'tomatometer_status'\n",
    "feature_columns = [col for col in final_df.columns if col != target_column]\n",
    "\n",
    "X = final_df[feature_columns]\n",
    "y = final_df[target_column]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Testing set size: {X_test.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'm/1001567-bad_news_bears'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14416\\3249166033.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Initialize the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Make predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1147\u001b[0m                 skip_parameter_validation=(\n\u001b[0;32m   1148\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m                 )\n\u001b[0;32m   1150\u001b[0m             ):\n\u001b[1;32m-> 1151\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    344\u001b[0m         \"\"\"\n\u001b[0;32m    345\u001b[0m         \u001b[1;31m# Validate or convert input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m         X, y = self._validate_data(\n\u001b[0m\u001b[0;32m    349\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         )\n\u001b[0;32m    351\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    617\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m\"estimator\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    622\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1143\u001b[0m         raise ValueError(\n\u001b[0;32m   1144\u001b[0m             \u001b[1;34mf\"{estimator_name} requires y to be passed, but the target y is None\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m         )\n\u001b[0;32m   1146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m   1148\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    914\u001b[0m                         )\n\u001b[0;32m    915\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 918\u001b[1;33m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    919\u001b[0m                 raise ValueError(\n\u001b[0;32m    920\u001b[0m                     \u001b[1;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    921\u001b[0m                 ) from complex_warning\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[1;31m# Use NumPy API to support order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1996\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1997\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1998\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1999\u001b[0m         if (\n\u001b[0;32m   2000\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2001\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'm/1001567-bad_news_bears'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rotten_tomatoes_link     object\n",
      "critic_name              object\n",
      "top_critic                int32\n",
      "publisher_name            int32\n",
      "review_type               int32\n",
      "                         ...   \n",
      "year                    float64\n",
      "years                   float64\n",
      "york                    float64\n",
      "young                   float64\n",
      "younger                 float64\n",
      "Length: 1025, dtype: object\n",
      "rotten_tomatoes_link     object\n",
      "critic_name              object\n",
      "top_critic                int32\n",
      "publisher_name            int32\n",
      "review_type               int32\n",
      "                         ...   \n",
      "year                    float64\n",
      "years                   float64\n",
      "york                    float64\n",
      "young                   float64\n",
      "younger                 float64\n",
      "Length: 1025, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtypes)\n",
    "print(X_test.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric columns: Index(['rotten_tomatoes_link', 'critic_name', 'review_score', 'review_date',\n",
      "       'movie_title', 'critics_consensus', 'original_release_date',\n",
      "       'streaming_release_date', 'runtime', 'tomatometer_rating',\n",
      "       ...\n",
      "       'world', 'worse', 'worth', 'writer', 'wrong', 'year', 'years', 'york',\n",
      "       'young', 'younger'],\n",
      "      dtype='object', length=1012)\n"
     ]
    }
   ],
   "source": [
    "non_numeric_columns = X_train.select_dtypes(include=['object', 'float64']).columns\n",
    "print(\"Non-numeric columns:\", non_numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([X_train, X_test], axis=0)\n",
    "\n",
    "categorical_columns = combined.select_dtypes(include=['object']).columns\n",
    "\n",
    "combined_encoded = pd.get_dummies(combined, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "X_train_encoded = combined_encoded.iloc[:X_train.shape[0], :]\n",
    "X_test_encoded = combined_encoded.iloc[X_train.shape[0]:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_encoded shape: (39965, 16124)\n",
      "X_test_encoded shape: (9992, 16124)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train_encoded shape:\", X_train_encoded.shape)\n",
    "print(\"X_test_encoded shape:\", X_test_encoded.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features: Index(['top_critic', 'publisher_name', 'review_type', 'review_score',\n",
      "       'content_rating', 'genres', 'directors', 'authors', 'actors', 'runtime',\n",
      "       ...\n",
      "       'streaming_release_date_2020-03-12',\n",
      "       'streaming_release_date_2020-03-13',\n",
      "       'streaming_release_date_2020-04-07',\n",
      "       'streaming_release_date_2020-04-17',\n",
      "       'streaming_release_date_2020-04-27',\n",
      "       'streaming_release_date_2020-05-24',\n",
      "       'streaming_release_date_2020-09-20',\n",
      "       'streaming_release_date_2020-10-13',\n",
      "       'streaming_release_date_2020-10-15', 'streaming_release_date_Unknown'],\n",
      "      dtype='object', length=16124)\n",
      "Testing features: Index(['top_critic', 'publisher_name', 'review_type', 'review_score',\n",
      "       'content_rating', 'genres', 'directors', 'authors', 'actors', 'runtime',\n",
      "       ...\n",
      "       'streaming_release_date_2020-03-12',\n",
      "       'streaming_release_date_2020-03-13',\n",
      "       'streaming_release_date_2020-04-07',\n",
      "       'streaming_release_date_2020-04-17',\n",
      "       'streaming_release_date_2020-04-27',\n",
      "       'streaming_release_date_2020-05-24',\n",
      "       'streaming_release_date_2020-09-20',\n",
      "       'streaming_release_date_2020-10-13',\n",
      "       'streaming_release_date_2020-10-15', 'streaming_release_date_Unknown'],\n",
      "      dtype='object', length=16124)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training features:\", X_train_encoded.columns)\n",
    "print(\"Testing features:\", X_test_encoded.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "model.fit(X_train_encoded, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Certified-Fresh       1.00      1.00      1.00      2793\n",
      "          Fresh       1.00      1.00      1.00      2913\n",
      "         Rotten       1.00      1.00      1.00      4286\n",
      "\n",
      "       accuracy                           1.00      9992\n",
      "      macro avg       1.00      1.00      1.00      9992\n",
      "   weighted avg       1.00      1.00      1.00      9992\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2793    0    0]\n",
      " [   0 2913    0]\n",
      " [   0    0 4286]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "model.fit(X_train_encoded, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_encoded)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of 1.0: This means the model correctly predicted all instances in the test set.\n",
    "\n",
    "**Classification Report:**\n",
    "\n",
    "Precision, Recall, F1-score: All are 1.00 for each class (Certified-Fresh, Fresh, Rotten). This indicates that the model is perfectly classifying each class without any false positives or false negatives.\n",
    "Support: The number of true instances for each class, which matches the number of instances in your confusion matrix.\n",
    "\n",
    "**Confusion Matrix:**\n",
    "\n",
    "The matrix shows all true positives and no misclassifications. Each row and column correctly represent the classes, confirming that every prediction is accurate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
